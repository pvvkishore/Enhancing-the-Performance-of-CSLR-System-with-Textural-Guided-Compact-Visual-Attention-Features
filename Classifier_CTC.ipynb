{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce1d89e8-14b5-4421-a6a7-43d483441926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 3.916597843170166\n",
      "Epoch 2/30, Loss: 3.8330509662628174\n",
      "Epoch 3/30, Loss: 3.6905856132507324\n",
      "Epoch 4/30, Loss: 3.52860689163208\n",
      "Epoch 5/30, Loss: 3.6336162090301514\n",
      "Epoch 6/30, Loss: 3.406665802001953\n",
      "Epoch 7/30, Loss: 3.388509750366211\n",
      "Epoch 8/30, Loss: 3.124215841293335\n",
      "Epoch 9/30, Loss: 3.1875786781311035\n",
      "Epoch 10/30, Loss: 2.8808376789093018\n",
      "Epoch 11/30, Loss: 2.5267772674560547\n",
      "Epoch 12/30, Loss: 2.152298927307129\n",
      "Epoch 13/30, Loss: 2.6620020866394043\n",
      "Epoch 14/30, Loss: 2.0018093585968018\n",
      "Epoch 15/30, Loss: 1.9864614009857178\n",
      "Epoch 16/30, Loss: 1.67706298828125\n",
      "Epoch 17/30, Loss: 1.457363486289978\n",
      "Epoch 18/30, Loss: 0.9757229089736938\n",
      "Epoch 19/30, Loss: 0.924480676651001\n",
      "Epoch 20/30, Loss: 0.7676116228103638\n",
      "Epoch 21/30, Loss: 0.8261665105819702\n",
      "Epoch 22/30, Loss: 0.30404895544052124\n",
      "Epoch 23/30, Loss: 0.40318262577056885\n",
      "Epoch 24/30, Loss: 0.44911935925483704\n",
      "Epoch 25/30, Loss: 0.3758374750614166\n",
      "Epoch 26/30, Loss: 0.17474721372127533\n",
      "Epoch 27/30, Loss: 0.18727947771549225\n",
      "Epoch 28/30, Loss: 0.06345482915639877\n",
      "Epoch 29/30, Loss: 0.12678945064544678\n",
      "Epoch 30/30, Loss: 0.11540617793798447\n",
      "Predicted Word: children\n",
      "Predicted Sentence: children under government training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\AppData\\Local\\Temp\\ipykernel_13060\\3713792845.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_feature = torch.tensor(test_feature, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Define the GlossClassifier\n",
    "class GlossClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(GlossClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),  # Hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)  # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Function to load data\n",
    "def load_data(output_folder):\n",
    "    pooled_features = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, filename in enumerate(os.listdir(output_folder)):\n",
    "        feature_path = os.path.join(output_folder, filename)\n",
    "        feature = np.load(feature_path)  # Load the pooled feature\n",
    "        pooled_features.append(feature)\n",
    "        labels.append(idx)  # Assign a label (modify as per your dataset)\n",
    "\n",
    "    pooled_features = torch.tensor(pooled_features, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)  # Convert labels to tensor\n",
    "\n",
    "    return pooled_features, labels\n",
    "\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=30):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for features, target in dataloader:\n",
    "            features = features.squeeze(1)  # Adjust the dimensions if needed\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "# Function to test the model\n",
    "def test_model(model, test_feature, target_sentences):\n",
    "    model.eval()\n",
    "    test_feature = torch.tensor(test_feature, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "    output = model(test_feature)\n",
    "\n",
    "    output = output.squeeze(1)  # Now the shape will be [1, num_classes]\n",
    "    predicted_label = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    predicted_word = class_to_word[predicted_label]\n",
    "    print(f\"Predicted Word: {predicted_word}\")\n",
    "\n",
    "    # Map the predicted word to the corresponding sentence from target_sentences\n",
    "    predicted_sentence = get_sentence_from_gloss(predicted_word, target_sentences)\n",
    "    print(f\"Predicted Sentence: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "# Function to map predicted gloss to a sentence\n",
    "def get_sentence_from_gloss(predicted_word, target_sentences):\n",
    "    for sentence in target_sentences:\n",
    "        if predicted_word in sentence.lower():  # Case-insensitive match\n",
    "            return sentence\n",
    "    return \"Sentence not found for the predicted word!\"\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Path to the folder containing the pooled features\n",
    "    output_folder = \"C:/Users/prath/OneDrive/Desktop/pooled features10\"\n",
    "    \n",
    "    # Load the data\n",
    "    pooled_features, labels = load_data(output_folder)\n",
    "\n",
    "    # Create a dataset and dataloader\n",
    "    dataset = TensorDataset(pooled_features, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # Define the model, loss, and optimizer\n",
    "    input_dim = 2048  # Adjust according to your feature size\n",
    "    num_classes = len(set(labels.numpy()))  # Number of unique glosses\n",
    "\n",
    "    model = GlossClassifier(input_dim, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, dataloader, criterion, optimizer, num_epochs=30)\n",
    "\n",
    "    # Example: Predict gloss for a new feature (e.g., the 6th feature from the dataset)\n",
    "    class_to_word = ['goodmorning', 'hearingimpaired', 'communication', 'news', 'meetings', 'primeMinister', \n",
    "                     'namaskar', 'indetail', 'watching', 'both', 'activities', 'chaired', 'children', \n",
    "                     'development', 'earlier', 'fire', 'fourteen', 'government', 'homeminister', 'india', \n",
    "                     'instructed', 'interaction', 'inthis', 'more', 'movingon', 'one', 'reviewed', 'situation', \n",
    "                     'spoke', 'technological', 'terrorists', 'thanks', 'thatsit', 'there', 'today', 'tools', \n",
    "                     'two', 'under', 'yesterday', 'youare', 'health', 'imprisonment', 'phone', 'training', \n",
    "                     'krishna', 'wrong', 'train', 'global', 'men', 'story']\n",
    "\n",
    "    target_sentences = [\n",
    "        'Youare reviewed the story',\n",
    "        'children under government training',\n",
    "        'The situation today is critical',\n",
    "        'India meetings chaired by the primeMinister',\n",
    "        'Thanks for your communication earlier',\n",
    "        'children watched the communication indetail',     \n",
    "        'Homeminister instructed meetings yesterday',     \n",
    "        'Both terrorists and government spoke earlier',   \n",
    "        'India movingon with technological development',\n",
    "        'Thanks for the health training today',\n",
    "        'Krishna interacted with the PrimeMinister today',\n",
    "        'The phone situation was wrong yesterday',\n",
    "        'The fire situation was reviewed by the government',\n",
    "        'Men imprisoned for activities involving terrorists',\n",
    "        'Fourteen men chaired the government meetings',       \n",
    "        'The primeMinister spoke about global communication',\n",
    "        'Yesterday the Homeminister instructed further action',\n",
    "        'The terrorists reviewed technological tools for training',\n",
    "        'Movingon from imprisonment the story continues today',\n",
    "        'Inthis situation more interaction is needed',\n",
    "        'The development of new tools was discussed in meetings',\n",
    "        'primeMinister chaired meetings yesterday'\n",
    "    ]\n",
    "\n",
    "    test_feature = pooled_features[12]  # Test with the 6th feature (adjust as needed)\n",
    "    test_model(model, test_feature, target_sentences)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9f4cb-4e55-43fe-a2d7-6e53dda86e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040cfd4-b379-4f84-83d6-2b8eb9a57251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c218f9-3129-4c41-aee1-18cfa3fffb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b58277-f3d5-44c2-b8a9-792019f3f52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187964a3-72f5-4d36-a2d6-2c4ef08db34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107d92c-d07c-4310-a17f-066ddcccf846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b9a14-fe5c-43ac-b754-5c538fd47447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab6b7c-f01e-41c2-aebb-d04204f9e4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2ec1c-fc95-4c3a-8e38-94aea833c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d7b8e-c950-4e7a-8d34-be240a8c9df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee77ca6-39ee-41ac-9ac1-e7b3ed338716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
