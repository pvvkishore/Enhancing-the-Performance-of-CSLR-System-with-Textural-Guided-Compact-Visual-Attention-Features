{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fed751-b648-43c6-8e87-b0b235d8f645",
   "metadata": {},
   "source": [
    "RESNET_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9b1711-a355-4ff6-91b0-7b8af237f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492fca85-d9e4-424a-85c8-a05affc14df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, root_dir, words_list, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = sorted(os.listdir(root_dir), key=int)  # Ensure numeric sorting (1 to 50)\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        for class_id, class_name in enumerate(self.classes):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            frames = sorted(os.listdir(class_path), key=lambda x: int(x.split('.')[0]))  # Ensure numeric frame sorting\n",
    "            for frame in frames:\n",
    "                self.data.append((os.path.join(class_path, frame), class_id))\n",
    "        self.words_list = words_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_path, class_id = self.data[idx]\n",
    "        image = Image.open(frame_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84da653-d086-478d-80ea-a02708c9e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and Parameters\n",
    "root_dir = \"C:/Users/prath/OneDrive/Desktop/PAPER 1/50 frames\"  # Replace with your folder path\n",
    "output_features_dir = \"C:/Users/prath/OneDrive/Desktop/resnet18_features1\"  # Replace with the output directory\n",
    "os.makedirs(output_features_dir, exist_ok=True)\n",
    "\n",
    "# List of words (provided by you)\n",
    "words_list = [\n",
    "    'goodmorning', 'hearingimpaired', 'communication', 'news', 'meetings',\n",
    "    'primeMinister', 'namaskar', 'indetail', 'watching', 'both',\n",
    "    'activities', 'chaired', 'children', 'development', 'earlier',\n",
    "    'fire', 'fourteen', 'government', 'homeminister', 'india',\n",
    "    'instructed', 'interaction', 'inthis', 'more', 'movingon',\n",
    "    'one', 'reviewed', 'situation', 'spoke', 'technological',\n",
    "    'terrorists', 'thanks', 'thatsit', 'there', 'today',\n",
    "    'tools', 'two', 'under', 'yesterday', 'youare',\n",
    "    'health', 'imprisonment', 'phone', 'training', 'krishna',\n",
    "    'wrong', 'train', 'global', 'men', 'story'  # Replace with your actual words\n",
    "]\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Data Transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = FrameDataset(root_dir, words_list, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4d4350-ecc2-496a-88eb-24e3533caa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet-18 from Scratch\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        self.resnet = resnet18(weights=None)  # No pretrained weights\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)  # Custom output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = CustomResNet18(num_classes=50).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37dea60b-2b1a-48bc-b6c7-e77a36053a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5502, Accuracy: 57.28%\n",
      "Epoch [2/10], Loss: 0.1821, Accuracy: 95.76%\n",
      "Epoch [3/10], Loss: 0.0535, Accuracy: 99.20%\n",
      "Epoch [4/10], Loss: 0.0921, Accuracy: 98.08%\n",
      "Epoch [5/10], Loss: 0.0796, Accuracy: 98.28%\n",
      "Epoch [6/10], Loss: 0.0279, Accuracy: 99.28%\n",
      "Epoch [7/10], Loss: 0.0355, Accuracy: 99.20%\n",
      "Epoch [8/10], Loss: 0.0031, Accuracy: 99.96%\n",
      "Epoch [9/10], Loss: 0.0120, Accuracy: 99.72%\n",
      "Epoch [10/10], Loss: 0.0081, Accuracy: 99.88%\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f40aad8-11f0-4fd4-9244-d96712e06332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "model.eval()\n",
    "features_extractor = nn.Sequential(*list(model.resnet.children())[:-1]).cuda()  # Remove final layer\n",
    "with torch.no_grad():\n",
    "    for class_name in os.listdir(root_dir):\n",
    "        class_path = os.path.join(root_dir, class_name)\n",
    "        save_path = os.path.join(output_features_dir, class_name)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        for frame_name in sorted(os.listdir(class_path), key=lambda x: int(x.split('.')[0])):\n",
    "            frame_path = os.path.join(class_path, frame_name)\n",
    "            image = Image.open(frame_path).convert(\"RGB\")\n",
    "            if transform:\n",
    "                image = transform(image)\n",
    "            image = image.unsqueeze(0).cuda()\n",
    "            features = features_extractor(image).squeeze().cpu().numpy()\n",
    "            np.save(os.path.join(save_path, frame_name.split(\".\")[0] + \".npy\"), features)\n",
    "\n",
    "print(\"Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7b3ea-a482-42a8-8442-b3b9fdad9836",
   "metadata": {},
   "source": [
    "BI-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ccec900-2188-43b1-9b5f-d2a5395e6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List of words (provided by you)\n",
    "words_list = [\n",
    "    'goodmorning', 'hearingimpaired', 'communication', 'news', 'meetings',\n",
    "    'primeMinister', 'namaskar', 'indetail', 'watching', 'both',\n",
    "    'activities', 'chaired', 'children', 'development', 'earlier',\n",
    "    'fire', 'fourteen', 'government', 'homeminister', 'india',\n",
    "    'instructed', 'interaction', 'inthis', 'more', 'movingon',\n",
    "    'one', 'reviewed', 'situation', 'spoke', 'technological',\n",
    "    'terrorists', 'thanks', 'thatsit', 'there', 'today',\n",
    "    'tools', 'two', 'under', 'yesterday', 'youare',\n",
    "    'health', 'imprisonment', 'phone', 'training', 'krishna',\n",
    "    'wrong', 'train', 'global', 'men', 'story'  # Replace with your actual words\n",
    "]\n",
    "\n",
    "\n",
    "# Create word-to-index mapping\n",
    "word_to_index = {word: i for i, word in enumerate(words_list)}\n",
    "index_to_word = {i: word for i, word in enumerate(words_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0de989c-1ecd-41da-b358-9348560b3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, features_dir, words_list, sequence_length=50):\n",
    "        self.features_dir = features_dir\n",
    "        self.words_list = words_list\n",
    "        self.word_to_index = {word: i for i, word in enumerate(words_list)}\n",
    "        self.data = []\n",
    "\n",
    "        # Loop through each class (1 to 50)\n",
    "        for class_id in range(1, len(words_list) + 1):\n",
    "            class_path = os.path.join(features_dir, str(class_id))\n",
    "\n",
    "            # Load all 50 features for this class\n",
    "            feature_files = sorted(os.listdir(class_path), key=lambda x: int(x.split('.')[0]))\n",
    "            features = [np.load(os.path.join(class_path, f)) for f in feature_files]\n",
    "\n",
    "            # Stack into (sequence_length, input_dim) = (50, 512)\n",
    "            features = np.stack(features)  # Shape: (50, 512)\n",
    "\n",
    "            # Get the word index as the label\n",
    "            word_label = self.word_to_index[words_list[class_id - 1]]  # Convert word to index\n",
    "\n",
    "            self.data.append((features, word_label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, word_label = self.data[idx]\n",
    "        return torch.tensor(sequence, dtype=torch.float32), torch.tensor(word_label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7faa4585-44b0-4402-9425-6b11d5257bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim=512, hidden_dim=512, num_layers=2, num_classes=50):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # Output size = 50 (number of words)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # Shape: (batch_size, 50, 1024)\n",
    "        out = out[:, -1, :]  # Take the last timestep → Shape: (batch_size, 1024)\n",
    "        out = self.fc(out)  # Shape: (batch_size, 50) → Class logits\n",
    "        return out  # Predicts a word class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d7e09fa-b458-4356-a78c-bef6e2b47be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.0950, Accuracy: 0.00%\n",
      "Epoch [2/10], Loss: 3.6409, Accuracy: 14.00%\n",
      "Epoch [3/10], Loss: 2.7574, Accuracy: 66.00%\n",
      "Epoch [4/10], Loss: 1.4370, Accuracy: 88.00%\n",
      "Epoch [5/10], Loss: 0.8231, Accuracy: 96.00%\n",
      "Epoch [6/10], Loss: 0.5595, Accuracy: 94.00%\n",
      "Epoch [7/10], Loss: 0.4514, Accuracy: 98.00%\n",
      "Epoch [8/10], Loss: 0.2631, Accuracy: 98.00%\n",
      "Epoch [9/10], Loss: 0.1527, Accuracy: 100.00%\n",
      "Epoch [10/10], Loss: 0.0751, Accuracy: 100.00%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "input_dim = 512  # ResNet feature size\n",
    "hidden_dim = 512\n",
    "num_layers = 2\n",
    "num_classes = 50  # 50 words as labels\n",
    "\n",
    "# Load dataset\n",
    "features_dir = \"C:/Users/prath/OneDrive/Desktop/resnet18_features\"\n",
    "dataset = FeatureDataset(features_dir, words_list)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Define BiLSTM Model\n",
    "model = BiLSTMModel(input_dim, hidden_dim, num_layers, num_classes).cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for features, labels in dataloader:\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(features)  # Shape: (batch_size, 50) → Word logits\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80923d50-f129-4d49-ae22-4861a64273ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "# Output folder for BiLSTM features\n",
    "output_features_dir = \"C:/Users/prath/OneDrive/Desktop/bilstm_features_10\"\n",
    "os.makedirs(output_features_dir, exist_ok=True)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for class_id in range(1, 51):  # Loop through 50 classes\n",
    "        class_path = os.path.join(features_dir, str(class_id))\n",
    "\n",
    "        feature_files = sorted(os.listdir(class_path), key=lambda x: int(x.split('.')[0]))\n",
    "        features = []\n",
    "\n",
    "        for f in feature_files:\n",
    "            feature_path = os.path.join(class_path, f)\n",
    "            feature = np.load(feature_path)  # Shape: (512,)\n",
    "            features.append(feature)\n",
    "\n",
    "        if len(features) == 50:  # Ensure we have exactly 50 frames\n",
    "            features = np.stack(features)  # Shape: (50, 512)\n",
    "            features = torch.tensor(features, dtype=torch.float32).unsqueeze(0).cuda()  # Shape: (1, 50, 512)\n",
    "            \n",
    "            output = model.lstm(features)[0][:, -1, :].cpu().numpy()  # Extract last hidden state → Shape: (1, 1024)\n",
    "            np.save(os.path.join(output_features_dir, f\"{class_id}.npy\"), output.squeeze(0))  # Shape: (1024,)\n",
    "\n",
    "print(\"BiLSTM feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896aadb-d151-4912-8b2d-7fdf254290b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
